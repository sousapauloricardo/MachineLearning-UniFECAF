{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73518048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeiras linhas do dataset Iris:\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "  species  \n",
      "0  setosa  \n",
      "1  setosa  \n",
      "2  setosa  \n",
      "3  setosa  \n",
      "4  setosa  \n"
     ]
    }
   ],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier # RandomForestClassifier: Um classificador baseado em uma floresta aleatória (Random Forest), que utiliza múltiplas árvores de \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Carregando o dataset Iris\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Extraindo os dados e criando um DataFrame\n",
    "X = iris.data  # Características (features)\n",
    "y = iris.target  # Classes (target)\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names\n",
    "\n",
    "# Criando um DataFrame para melhor visualização\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['species'] = [target_names[i] for i in y]\n",
    "\n",
    "# Visualizando as primeiras linhas do dataset\n",
    "print(\"Primeiras linhas do dataset Iris:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f35bb3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir em conjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42)  \n",
    "    # test_size=0.25: Define que 25% dos dados serão usados para o conjunto de teste.\n",
    "    # random_state=42: Este parâmetro garante que a divisão dos dados seja reproduzível.\n",
    "    # X_train terá 75% dos dados, enquanto X_test terá 25%.\n",
    "    # y_train terá os rótulos para os 75% dos dados de treino, enquanto y_test terá os rótulos para os 25% dos dados de teste.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42fcc60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() # Cria um objeto para escalonar os dados. \n",
    "# StandardScaler: Usado para escalonamento (normalização) das features, transformando os dados para que tenham média zero e desvio padrão um. \n",
    "X_train_scaled = scaler.fit_transform(X_train) # aplica o ajuste e a transformação de uma vez.\n",
    "# OneHotEncoder: Codifica variáveis categóricas em uma forma que o modelo possa entender.\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "# SimpleImputer: Utilizado para lidar com valores ausentes nos dados (missing values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c873296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo mais complexo com diferentes tipos de dados\n",
    "# (normalmente usado quando temos features numéricas e categóricas)\n",
    "numeric_features = [0, 1, 2, 3]  # índices das colunas numéricas\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "# ColumnTransformer: Permite aplicar transformações diferentes em colunas específicas do conjunto de dados.\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f65b6e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline simples com pré-processamento e modelo\n",
    "pipeline = Pipeline(steps=[\n",
    "    # Pipeline é uma forma de encapsular um fluxo completo de transformação dos dados e treinamento de um modelo em uma única estrutura.\n",
    "    ('preprocessor', preprocessor), # Ele aplica as transformações definidas anteriormente no ColumnTransformer\n",
    "    ('classifier', RandomForestClassifier(random_state=42)) # É o modelo de aprendizado de máquina que será treinado. Aqui, está sendo utilizado o RandomForestClassifier\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "178c4a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar o pipeline\n",
    "pipeline.fit(X_train, y_train)   \n",
    "# O preprocessor aplica as transformações (como imputação e escalonamento) nas features de treinamento (X_train).\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = pipeline.predict(X_test) \n",
    "# Após o treinamento, o pipeline é capaz de fazer previsões nos dados de teste (X_test), aplicando o mesmo pré-processamento aos dados de entrada antes de fazer as previsões com o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f8d4b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 1.0000\n",
      "Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        15\n",
      "  versicolor       1.00      1.00      1.00        11\n",
      "   virginica       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        38\n",
      "   macro avg       1.00      1.00      1.00        38\n",
      "weighted avg       1.00      1.00      1.00        38\n",
      "\n",
      "Matriz de confusão:\n",
      "[[15  0  0]\n",
      " [ 0 11  0]\n",
      " [ 0  0 12]]\n"
     ]
    }
   ],
   "source": [
    "# Avaliar a precisão \n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) \n",
    "print(f\"Acurácia: {accuracy:.4f}\") \n",
    "\n",
    "# Relatório de classificação \n",
    "print(\"Relatório de classificação:\") \n",
    "print(metrics.classification_report(y_test, y_pred, \n",
    "                                   target_names=iris.target_names)) \n",
    "\n",
    "# Matriz de confusão \n",
    "cm = metrics.confusion_matrix(y_test, y_pred) \n",
    "print(\"Matriz de confusão:\") \n",
    "print(cm) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ec0e77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 1.0\n",
      "Matriz de Confusão:\n",
      " [[15  0  0]\n",
      " [ 0 11  0]\n",
      " [ 0  0 12]]\n",
      "Precisão: 1.0\n",
      "Recall: 1.0\n",
      "F1-Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"Acurácia:\", accuracy)\n",
    "print(\"Matriz de Confusão:\\n\", conf_matrix)\n",
    "print(\"Precisão:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8c202a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros: {'classifier__max_depth': None, 'classifier__n_estimators': 200}\n",
      "Melhor pontuação: 0.9462450592885375\n",
      "Acurácia com o melhor modelo: 1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Definir parâmetros para busca\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20, 30]\n",
    "}\n",
    "\n",
    "# Criar objeto de busca em grade\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline, param_grid, cv=5, scoring='accuracy'\n",
    ")\n",
    "\n",
    "# Executar busca\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Melhores parâmetros\n",
    "print(\"Melhores parâmetros:\", grid_search.best_params_)\n",
    "print(\"Melhor pontuação:\", grid_search.best_score_)\n",
    "\n",
    "# Usar o melhor modelo\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "print(f\"Acurácia com o melhor modelo: {metrics.accuracy_score(y_test, y_pred_best):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
